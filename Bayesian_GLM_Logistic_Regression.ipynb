{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General GLM for classification:\n",
    "* https://docs.pymc.io/en/v3/pymc-examples/examples/generalized_linear_models/GLM-logistic.html\n",
    "\n",
    "\n",
    "An example of Spike and slab:\n",
    "* https://www.kaggle.com/code/melondonkey/bayesian-spike-and-slab-in-pymc3/notebook\n",
    "\n",
    "\n",
    "An example with adding priors:\n",
    "* https://discourse.pymc.io/t/linear-regression-with-positivity-constraint/2598/4?u=junpenglao\n",
    "* https://discourse.pymc.io/t/glm-logistic-regression-with-custom-prior-in-pymc3-v-3-6/2644/3\n",
    "\n",
    "Generating out of sample predictions:\n",
    "* https://docs.pymc.io/en/v3/pymc-examples/examples/generalized_linear_models/GLM-out-of-sample-predictions.html\n",
    "* https://bpostance.github.io/posts/pymc3-predictions/\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "from collections import OrderedDict\n",
    "from time import time\n",
    "\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import seaborn\n",
    "import theano as thno\n",
    "import theano.tensor as T\n",
    "\n",
    "from scipy import integrate\n",
    "from scipy.optimize import fmin_powell\n",
    "\n",
    "print(f\"Running on PyMC3 v{pm.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models(df, upper_order=5):\n",
    "    \"\"\"\n",
    "    Convenience function:\n",
    "    Fit a range of pymc3 models of increasing polynomial complexity.\n",
    "    Suggest limit to max order 5 since calculation time is exponential.\n",
    "    \"\"\"\n",
    "\n",
    "    models, traces = OrderedDict(), OrderedDict()\n",
    "\n",
    "    for k in range(1, upper_order + 1):\n",
    "\n",
    "        nm = f\"k{k}\"\n",
    "        fml = create_poly_modelspec(k)\n",
    "\n",
    "        with pm.Model() as models[nm]:\n",
    "\n",
    "            print(f\"\\nRunning: {nm}\")\n",
    "            pm.glm.GLM.from_formula(fml, df, family=pm.glm.families.Binomial())\n",
    "\n",
    "            traces[nm] = pm.sample(1000, tune=1000, init=\"adapt_diag\", return_inferencedata=True)\n",
    "\n",
    "    return models, traces\n",
    "\n",
    "\n",
    "def plot_traces(traces, model, retain=0):\n",
    "    \"\"\"\n",
    "    Convenience function:\n",
    "    Plot traces with overlaid means and values\n",
    "    \"\"\"\n",
    "    with model:\n",
    "        ax = az.plot_trace(\n",
    "            traces[-retain:],\n",
    "            lines=tuple([(k, {}, v[\"mean\"]) for k, v in az.summary(traces[-retain:]).iterrows()]),\n",
    "        )\n",
    "\n",
    "        for i, mn in enumerate(az.summary(traces[-retain:])[\"mean\"]):\n",
    "            ax[i, 0].annotate(\n",
    "                f\"{mn:.2f}\",\n",
    "                xy=(mn, 0),\n",
    "                xycoords=\"data\",\n",
    "                xytext=(5, 10),\n",
    "                textcoords=\"offset points\",\n",
    "                rotation=90,\n",
    "                va=\"bottom\",\n",
    "                fontsize=\"large\",\n",
    "                color=\"#AA0022\",\n",
    "            )\n",
    "\n",
    "\n",
    "def create_poly_modelspec(k=1):\n",
    "    \"\"\"\n",
    "    Convenience function:\n",
    "    Create a polynomial modelspec string for patsy\n",
    "    \"\"\"\n",
    "    return (\n",
    "        \"income ~ educ + hours + age \" + \" \".join([f\"+ np.power(age,{j})\" for j in range(2, k + 1)])\n",
    "    ).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\",\n",
    "    header=None,\n",
    "    names=[\n",
    "        \"age\",\n",
    "        \"workclass\",\n",
    "        \"fnlwgt\",\n",
    "        \"education-categorical\",\n",
    "        \"educ\",\n",
    "        \"marital-status\",\n",
    "        \"occupation\",\n",
    "        \"relationship\",\n",
    "        \"race\",\n",
    "        \"sex\",\n",
    "        \"captial-gain\",\n",
    "        \"capital-loss\",\n",
    "        \"hours\",\n",
    "        \"native-country\",\n",
    "        \"income\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = raw_data[~pd.isnull(raw_data[\"income\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"native-country\"] == \" United-States\"].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income = 1 * (data[\"income\"] == \" >50K\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[[\"age\", \"educ\", \"hours\"]]\n",
    "\n",
    "# Scale age by 10, it helps with model convergence.\n",
    "data[\"age\"] = data[\"age\"] / 10.0\n",
    "data[\"age2\"] = np.square(data[\"age\"])\n",
    "data[\"income\"] = income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = seaborn.pairplot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "corr = data.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = seaborn.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "seaborn.heatmap(\n",
    "    corr,\n",
    "    mask=mask,\n",
    "    cmap=cmap,\n",
    "    vmax=0.3,\n",
    "    linewidths=0.5,\n",
    "    cbar_kws={\"shrink\": 0.5},\n",
    "    ax=ax,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as logistic_model:\n",
    "    pm.glm.GLM.from_formula(\n",
    "        \"income ~ age + age2 + educ + hours\", data, family=pm.glm.families.Binomial()\n",
    "    )\n",
    "    trace = pm.sample(1000, tune=1000, init=\"adapt_diag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.model_to_graphviz(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_traces(trace, logistic_model);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 7))\n",
    "seaborn.jointplot(trace[\"age\"], trace[\"educ\"], kind=\"hex\", color=\"#4CB391\")\n",
    "plt.xlabel(\"beta_age\")\n",
    "plt.ylabel(\"beta_educ\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm_full(trace, age, educ, hours):\n",
    "    shape = np.broadcast(age, educ, hours).shape\n",
    "    x_norm = np.asarray([np.broadcast_to(x, shape) for x in [age / 10.0, educ, hours]])\n",
    "    return 1 / (\n",
    "        1\n",
    "        + np.exp(\n",
    "            -(\n",
    "                trace[\"Intercept\"]\n",
    "                + trace[\"age\"] * x_norm[0]\n",
    "                + trace[\"age2\"] * (x_norm[0] ** 2)\n",
    "                + trace[\"educ\"] * x_norm[1]\n",
    "                + trace[\"hours\"] * x_norm[2]\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "# Linear model with hours == 50 and educ == 12\n",
    "lm = lambda x, samples: lm_full(samples, x, 12.0, 50.0)\n",
    "\n",
    "# Linear model with hours == 50 and educ == 16\n",
    "lm2 = lambda x, samples: lm_full(samples, x, 16.0, 50.0)\n",
    "\n",
    "# Linear model with hours == 50 and educ == 19\n",
    "lm3 = lambda x, samples: lm_full(samples, x, 19.0, 50.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the posterior predictive distributions of P(income > $50K) vs. age\n",
    "pm.plot_posterior_predictive_glm(\n",
    "    trace, eval=np.linspace(25, 75, 1000), lm=lm, samples=100, color=\"blue\", alpha=0.15\n",
    ")\n",
    "pm.plot_posterior_predictive_glm(\n",
    "    trace,\n",
    "    eval=np.linspace(25, 75, 1000),\n",
    "    lm=lm2,\n",
    "    samples=100,\n",
    "    color=\"green\",\n",
    "    alpha=0.15,\n",
    ")\n",
    "pm.plot_posterior_predictive_glm(\n",
    "    trace, eval=np.linspace(25, 75, 1000), lm=lm3, samples=100, color=\"red\", alpha=0.15\n",
    ")\n",
    "\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "blue_line = mlines.Line2D([\"lm\"], [], color=\"b\", label=\"High School Education\")\n",
    "green_line = mlines.Line2D([\"lm2\"], [], color=\"g\", label=\"Bachelors\")\n",
    "red_line = mlines.Line2D([\"lm3\"], [], color=\"r\", label=\"Grad School\")\n",
    "plt.legend(handles=[blue_line, green_line, red_line], loc=\"lower right\")\n",
    "plt.ylabel(\"P(Income > $50K)\")\n",
    "plt.xlabel(\"Age\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = trace[\"educ\"]\n",
    "plt.hist(np.exp(b), bins=20, density=True)\n",
    "plt.xlabel(\"Odds Ratio\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb, ub = np.percentile(b, 2.5), np.percentile(b, 97.5)\n",
    "\n",
    "print(\"P({:.3f} < O.R. < {:.3f}) = 0.95\".format(np.exp(lb), np.exp(ub)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_lin, traces_lin = run_models(data, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trace_dict = dict()\n",
    "for nm in [\"k1\", \"k2\", \"k3\"]:\n",
    "    model_trace_dict.update({nm: traces_lin[nm]})\n",
    "\n",
    "dfwaic = az.compare(model_trace_dict, ic=\"WAIC\", scale=\"deviance\")\n",
    "az.plot_compare(dfwaic);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -n -u -v -iv -w"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
